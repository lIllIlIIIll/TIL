## 추천시스템 

- 인기도 기반 추천 : 모든 사용자에게 같은 추천을 제공하는 비개인화 추천 방식

- 연관규칙 : 데이터베이스 내 동시에 등장하는 빈도가 높은 컨텐츠의 조합을 찾아내는 방식

- 콘텐츠 기반 추천 : 특정 유저가 특정 장르를 선호하면 그 장르를 추천하는 방식

- 협업 필터링 : 사용자들, 또는 아이템 사이의 유사성을 기반으로 작동하는 추천 시스템

  - 유사성 판단 : 코사인 유사도
 
  - 기억 기반 협업 필터링 : 각 사용자들이 각 아이템을 선호하는지 여부를 나타낸 행렬을 기반으로 유사성 판단
 
  - 잠재 요인 분석 : 특정 피쳐에 대한 선호를 나타내는 잠재요인을 찾아내도록 학습
 
    - 잠재요인 : 임베딩과 같은 개념
   
## 시계열 데이터

- 시계열 데이터 : 일반적으로 동일한 시간 간격마다 연속된 시각에서 취한 순차적 데이터

- 순차적 데이터 : 어떤 순서를 가지는 데이터

- 규칙 성분(체계적 성분) : 시간에 따라 보이는 데이터의 패턴, 경향성에 의해 설명 가능한 예측 가능한 변동 성분

  - 추세 : 데이터가 단기적으로 증감하더라도 장기적으로는 점차 증가 or 감소하는 등의 방향성을 보이는 것
 
  - 계절성 : 정기적으로 데이터가 변화하는 것
 
  - 순환성 : 주기적으로 데이터가 변화하나 일정하지 않은 주기로 변화
 
- 기술적 분석 : 과거 데이터를 이해하기 위한 분석과정

- 예측적 분석 : 미래의 데이터를 예측하기 위해 과거 데이터를 분석하는 것

- 독립 항등 분포 : 어떤 확률변수들이같은 확률분포로부터 생성된 독립적인 샘플일 때 각 변수

  - gamlber's paradox : 주사위를 굴려서 특정 눈이 나올 확률 / 10일 연속 비가 오고 다음날 비가 올 확률
 
- 마르코프 속성 : 랜덤 프로세스의 미래 상태에 대한 조건부 확률 분포가 현재 상태에만 의존

- 시계열의 정상성

  - 정상성 데이터는 데이터를 생성하는 분포가 시간에 따라 변하지 않고 동일하게 유지
 
  - 비정상성 데이터는 반대로 생성 분포 자체가 시간에 지남에 따라 변화
 
- 시계열 데이터 분석 방법

  - 시계열의 진동수를 활용한 분석

    - 푸리에 분석
   
    - 스펙트럼 밀도 분석
   
    - 웨이브렛 분석
   
  - 시간에 따른 변화를 분석

    - 자기 회귀 모델 : 일정 스텝 수 만큼의 과거 데이터들을 입력값으로 선형회구모델을 학습
   
    - 이동평균 : p 기간 안의 시계열 데이터를 평균하여 시간 t의 추세-주기 측정
   
    - 추세 분석
   
    - 성분분해 : 시계열 데이터를 각 성분으로 분해하여 예측 or 계절성에 따른 변화 조정
   
## 모델 평가

- 정성평가 : 모델에 들어가는 입력값, 출력값을 사람이 직접 확인하면서 모델 성능 판단

- 정량평가 : 모델 성능이 얼마나 좋은지 수치로 나타내는 평가 지표 함수를 설정하여 이를 활용하여 모델 성능 판단

- 잘못된 데이터셋 분할

  - Data Leakage
 
  - 평가용 데이터셋 대표성 부족 (EX : 테스트셋이 너무 작음 / 구성이 불균형 등등)

- k-fold 교차 검증 : 데이터셋을 k개의 같은 크기의 부분집합으로 나누가 각 fold를 번갈아가며 검증용 데이터로 사용 → 각각의 결과를 평균내어 모델의 최종 성능 추정

- 일반화 성능 : 외삽, 내삽 성능을 포함하여 모델이 처음 접하는 데이터에서 얼마나 좋은 성능을 내는가?

  - 내삽 : 학습 데이터셋 범위 내 새로운 데이터를 예측 or 분류
 
  - 외삽 : 학습 데이터셋 범위 외 새로운 데이터를 예측 or 분류
 
- 분류에서 정량평가 지표

  - 혼동 행렬 : 이진 분류에서 모델의 예측치와 실제값에 따른 샘플 수를 표 형태로 나타낸 것
 
    |                   | 예측: Positive (1) | 예측: Negative (0) |
    |:------------------|:------------------:|:------------------:|
    | 실제: Positive (1) | True Positive (TP)  | False Negative (FN) |
    | 실제: Negative (0) | False Positive (FP) | True Negative (TN)  |

    - 정밀도 : TP / (TP + FP)
   
    - 재현율 : TP / (TP + FN)

    - F1 스코어 : 정밀도와 재현율을 동시에 비교하기 위해 조화평균을 취한 것
   
  - ROC Curve : 음성 / 양성 판단의 기준값 변화에 따라 TP/ FP의 비율이 변화하는 추세를 나타내는 곡선
 
  - AUC : ROC Curve의 아래쪽 영역의 넓이
 
- 회귀에서 정량평가 지표

  - MAE : 오차에 절댓값을 취한 것의 평균
 
  - MSE : 오차를 제곱한 것의 평균
 
  - RMSE : MSE의 제곱근
 
  - 이외
    
    - 편집거리 : 시계열 모델에서 사용되는 몇번의 삭제/추가를 거쳐야 출력값을 목표로 만들 수 있는가?
   
    - MOS, 모델 기반 정량평가 등
   
    - 컴퓨팅 자원 측면 : 인퍼런스 시간, 처리율, 메모리 샤용량 등

- 베이스라인 활용

  - 베이스라인 스코어 : 실험과정에서 비교용으로 사용하는 모델의 점수
  
  - 나이브 베이즈 분류기, k-최근접이웃 분류, 다중 로지스틱 회귀도 존재
 
  - 베이즈 최적 에러 : 현재 정량평가 방식에서 이론상 도달할 수 있는 이상적 분류 체계 성능
 
    - 휴먼 퍼포먼스 : 분류에서 판단이 어려운 문제가 있을 때, 사람의 분류능력을 이용하여 측정하는 것
   
- 모델 에러 분석

  - 모델 복잡도 : 모델이 더 복잡하고 어려운 데이터까지 학습할 수 있는 용량
 
  - 과적합 : 모델이 학습데이터의 패턴에만 과하게 학습된 것 (큰 분산 때문에 발생)

    - L1, L2 정규화 : 모델 파라미터의 L1/L2 norm을 손실함수 값에 더해 학습 과정에서 자연스럽게 파라미터 크기가 줄어들고, 이에 따라 모델 복잡도 감소
   
    - 학습 데이터 증강 : 정답 라벨이 바뀌지 않는 내에서 인풋 데이터를 여러 방법으로 변형시켜 새로운 데이터로 활용
   
    - 학습 곡선 활용 : 학습용 데이터셋과 검증용 데이터셋에서 측정되는 손실함수의 값의 변화를 그래프로 나타낸 것

      - 두 데이터셋 간 차이가 커지기 시작하는 시점에 학습을 일찍 종료(Early Stoopping)
 
  - 과소적합 : 모델이 학습 데이터셋 조차 전부 학습하지 못한 것 (큰 편향 때문에 발생)
 
  - 편향, 분산의 Trade Off 관계 : 모델의 편향과 분산은 한쪽이 낮아질 때 다른쪽이 높아지는 관계가 존재 → 적절한 균형점을 찾아야함
 
      - 하지만 풀고있는 문제가 충분히 복잡하고 어렵다면 과적합을 무시하고 모델 및 데이터의 복잡도를 계속해서 높이는 것이 좋을 수도 있다.
